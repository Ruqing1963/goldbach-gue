#!/usr/bin/env python3
"""
Paper III: Complete GUE Verification Script
å®Œæ•´çš„GUEç»Ÿè®¡éªŒè¯è„šæœ¬

åŒ…å«ä¸‰é‡è¯æ®æ£€éªŒ:
1. å¯¹æ•°ä¿®æ­£å¾‹: Î±(N) = Î±_âˆ + C/ln(N)
2. ååº¦æ¼”åŒ–: Î³â‚ â†’ 0
3. é—´è·åˆ†å¸ƒ: Ïƒ â†’ 0.707 (GUE)

ä½¿ç”¨æ–¹æ³•:
    python verify_gue_complete.py <csv_file>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import linregress, skew, kurtosis, norm
import sys
import os

def load_data(csv_file):
    """åŠ è½½æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½: {csv_file}")
    df = pd.read_csv(csv_file)
    print(f"   æ ·æœ¬: {len(df)}, N âˆˆ [{df['N'].min():,}, {df['N'].max():,}]")
    return df

def compute_statistics(df, n_bins=30):
    """è®¡ç®—å„NèŒƒå›´çš„ç»Ÿè®¡é‡"""
    # ç¡®å®šé¢„æµ‹åˆ—
    if 'Pred_Integral' in df.columns:
        pred_col = 'Pred_Integral'
    elif 'Pred' in df.columns:
        pred_col = 'Pred'
    else:
        raise ValueError("éœ€è¦é¢„æµ‹å€¼åˆ— (Pred_Integral æˆ– Pred)")
    
    bins = np.logspace(np.log10(df['N'].min()), np.log10(df['N'].max()), n_bins)
    results = []
    
    for i in range(len(bins)-1):
        low, high = bins[i], bins[i+1]
        subset = df[(df['N'] >= low) & (df['N'] < high)]
        
        if len(subset) > 30:
            residuals = subset['G_N'] - subset[pred_col]
            mean_pred = subset[pred_col].mean()
            
            # Fano factor
            alpha = residuals.var() / mean_pred
            
            # å½’ä¸€åŒ–æ®‹å·®
            normalized = residuals / np.sqrt(mean_pred)
            
            results.append({
                'N': np.sqrt(low * high),
                'ln_N': np.log(np.sqrt(low * high)),
                'inv_ln_N': 1/np.log(np.sqrt(low * high)),
                'alpha': alpha,
                'skewness': skew(normalized) if len(subset) > 50 else np.nan,
                'kurtosis': kurtosis(normalized) if len(subset) > 50 else np.nan,
                'std': normalized.std(),
                'n_samples': len(subset)
            })
    
    return pd.DataFrame(results)

def test_logarithmic_law(stats_df):
    """æ£€éªŒå¯¹æ•°ä¿®æ­£å¾‹"""
    print("\n" + "=" * 60)
    print("è¯æ®1: å¯¹æ•°ä¿®æ­£å¾‹ Î±(N) = Î±_âˆ + C/ln(N)")
    print("=" * 60)
    
    inv_ln = stats_df['inv_ln_N'].values
    alpha = stats_df['alpha'].values
    
    slope, intercept, r, p, se = linregress(inv_ln, alpha)
    
    print(f"\næ‹Ÿåˆç»“æœ:")
    print(f"  Î±_âˆ = {intercept:.4f}")
    print(f"  C = {slope:.4f}")
    print(f"  RÂ² = {r**2:.4f}")
    
    # åˆ¤æ–­
    if 0.45 <= intercept <= 0.65:
        verdict = "âœ… æ”¯æŒGUE (Î±_âˆ â‰ˆ 0.5)"
    elif intercept > 0.8:
        verdict = "âš ï¸ è¶‹å‘Poisson (Î±_âˆ â†’ 1)"
    else:
        verdict = f"ğŸ”¶ ä¸­é—´çŠ¶æ€ (Î±_âˆ â‰ˆ {intercept:.2f})"
    
    print(f"\nåˆ¤å®š: {verdict}")
    
    return intercept, slope, r**2

def test_skewness(stats_df):
    """æ£€éªŒååº¦æ¼”åŒ–"""
    print("\n" + "=" * 60)
    print("è¯æ®2: ååº¦æ¼”åŒ– Î³â‚ â†’ 0")
    print("=" * 60)
    
    valid = stats_df.dropna(subset=['skewness'])
    
    if len(valid) < 5:
        print("  âš ï¸ æ•°æ®ç‚¹ä¸è¶³")
        return np.nan
    
    # æŒ‰Nå¤§å°åˆ†ç»„
    small_N = valid[valid['N'] < valid['N'].median()]
    large_N = valid[valid['N'] >= valid['N'].median()]
    
    mean_small = small_N['skewness'].mean()
    mean_large = large_N['skewness'].mean()
    
    print(f"\nå°Nååº¦: {mean_small:.4f}")
    print(f"å¤§Nååº¦: {mean_large:.4f}")
    
    if abs(mean_large) < abs(mean_small):
        print(f"\nâœ… ååº¦è¶‹å‘0 (GUEå¯¹ç§°åˆ†å¸ƒ)")
    else:
        print(f"\nâš ï¸ ååº¦æœªæ˜æ˜¾æ”¹å–„")
    
    return mean_large

def test_spacing(stats_df):
    """æ£€éªŒé—´è·åˆ†å¸ƒ"""
    print("\n" + "=" * 60)
    print("è¯æ®3: é—´è·åˆ†å¸ƒ Ïƒ â†’ 0.707")
    print("=" * 60)
    
    # å¤§Nçš„æ ‡å‡†å·®
    large_N = stats_df[stats_df['N'] > stats_df['N'].median()]
    mean_std = large_N['std'].mean()
    
    gue_std = np.sqrt(0.5)  # â‰ˆ 0.707
    poisson_std = 1.0
    
    gue_diff = abs(mean_std - gue_std) / gue_std * 100
    poisson_diff = abs(mean_std - poisson_std) / poisson_std * 100
    
    print(f"\nè§‚æµ‹æ ‡å‡†å·®: {mean_std:.4f}")
    print(f"GUEç†è®ºå€¼: {gue_std:.4f} (åå·®: {gue_diff:.1f}%)")
    print(f"Poissonç†è®ºå€¼: {poisson_std:.4f} (åå·®: {poisson_diff:.1f}%)")
    
    if gue_diff < poisson_diff:
        print(f"\nâœ… æ›´æ¥è¿‘GUEåˆ†å¸ƒ")
    else:
        print(f"\nâš ï¸ æ›´æ¥è¿‘Poissonåˆ†å¸ƒ")
    
    return mean_std

def create_visualization(stats_df, df, output_file):
    """åˆ›å»ºå¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    fig.suptitle('GUE Statistics Verification', fontsize=14, fontweight='bold')
    
    # 1. å¯¹æ•°å¾‹
    ax1 = axes[0, 0]
    ax1.scatter(stats_df['inv_ln_N'], stats_df['alpha'], s=60, c='purple', edgecolor='black')
    slope, intercept, r, p, se = linregress(stats_df['inv_ln_N'], stats_df['alpha'])
    x_fit = np.linspace(0, stats_df['inv_ln_N'].max()*1.1, 100)
    ax1.plot(x_fit, intercept + slope*x_fit, 'b-', linewidth=2)
    ax1.axhline(0.5, color='green', linestyle='--', label='GUE')
    ax1.axhline(1.0, color='red', linestyle=':', label='Poisson')
    ax1.set_xlabel('1/ln(N)')
    ax1.set_ylabel('Î±')
    ax1.set_title(f'Logarithmic Law: Î±_âˆ = {intercept:.3f}')
    ax1.legend()
    
    # 2. ååº¦
    ax2 = axes[0, 1]
    valid_skew = stats_df.dropna(subset=['skewness'])
    ax2.scatter(np.log10(valid_skew['N']), valid_skew['skewness'], s=60, c='coral', edgecolor='black')
    ax2.axhline(0, color='green', linestyle='--', label='GUE (symmetric)')
    ax2.set_xlabel('logâ‚â‚€(N)')
    ax2.set_ylabel('Skewness')
    ax2.set_title('Skewness Evolution')
    ax2.legend()
    
    # 3. æ ‡å‡†å·®
    ax3 = axes[1, 0]
    ax3.scatter(np.log10(stats_df['N']), stats_df['std'], s=60, c='steelblue', edgecolor='black')
    ax3.axhline(np.sqrt(0.5), color='green', linestyle='--', label='GUE (0.707)')
    ax3.axhline(1.0, color='red', linestyle=':', label='Poisson (1.0)')
    ax3.set_xlabel('logâ‚â‚€(N)')
    ax3.set_ylabel('Normalized Std')
    ax3.set_title('Variance Compression')
    ax3.legend()
    
    # 4. åˆ†å¸ƒç›´æ–¹å›¾
    ax4 = axes[1, 1]
    pred_col = 'Pred_Integral' if 'Pred_Integral' in df.columns else 'Pred'
    large_N = df[df['N'] > df['N'].median()]
    residuals = (large_N['G_N'] - large_N[pred_col]) / np.sqrt(large_N[pred_col])
    ax4.hist(residuals, bins=40, density=True, alpha=0.6, color='purple', edgecolor='black')
    x = np.linspace(-3, 3, 200)
    ax4.plot(x, norm.pdf(x, 0, np.sqrt(0.5)), 'g-', linewidth=2, label='GUE')
    ax4.plot(x, norm.pdf(x, 0, 1.0), 'r--', linewidth=2, label='Poisson')
    ax4.set_xlabel('Normalized Residual')
    ax4.set_ylabel('Density')
    ax4.set_title('Spacing Distribution')
    ax4.legend()
    
    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\nğŸ–¼ï¸ å›¾è¡¨å·²ä¿å­˜: {output_file}")

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python verify_gue_complete.py <csv_file>")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    
    print("=" * 60)
    print("Paper III: Complete GUE Verification")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    df = load_data(csv_file)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    stats_df = compute_statistics(df)
    
    # ä¸‰é‡æ£€éªŒ
    alpha_inf, C, R2 = test_logarithmic_law(stats_df)
    skewness = test_skewness(stats_df)
    std = test_spacing(stats_df)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æ€»ç»“")
    print("=" * 60)
    
    print(f"""
    è¯æ®1 (å¯¹æ•°å¾‹): Î±_âˆ = {alpha_inf:.3f}
    è¯æ®2 (ååº¦):   Î³â‚ â†’ {skewness:.3f}
    è¯æ®3 (æ ‡å‡†å·®): Ïƒ = {std:.3f} (GUE: 0.707)
    
    ç»¼åˆåˆ¤å®š: {"âœ… æ”¯æŒGUEå‡è®¾" if 0.45 <= alpha_inf <= 0.65 else "âš ï¸ éœ€è¦æ›´å¤šæ•°æ®"}
    """)
    
    # å¯è§†åŒ–
    base_name = os.path.splitext(csv_file)[0]
    output_file = f"{base_name}_gue_verification.png"
    create_visualization(stats_df, df, output_file)

if __name__ == "__main__":
    main()
