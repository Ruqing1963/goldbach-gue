#!/usr/bin/env python3
"""
Paper III: Î± Evolution Data Generator (ä¼˜åŒ–ç‰ˆ)
ç”Ÿæˆ N = 10^6 åˆ° 10^8 çš„ Fano Factor æ¼”åŒ–æ•°æ®

ä¼˜åŒ–ç‰¹æ€§:
- ä½¿ç”¨numpyå‘é‡åŒ–æ“ä½œ
- æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- è‡ªåŠ¨Î±åˆ†æ

ä½¿ç”¨æ–¹æ³•:
    python generate_alpha_100M_optimized.py

è¾“å‡º:
    ALPHA_EVOLUTION_100M.csv
"""

import numpy as np
import pandas as pd
import time
import os
import sys

# ===== é…ç½®å‚æ•° =====
START_N = 1_000_000      # èµ·å§‹N
END_N = 100_000_000      # ç»ˆæ­¢N (1äº¿)
POINTS_PER_DECADE = 100  # æ¯ä¸ªæ•°é‡çº§çš„é‡‡æ ·ç‚¹æ•°ï¼ˆå·²ä¼˜åŒ–ï¼‰
C2 = 0.6601618158        # å­ªç”Ÿç´ æ•°å¸¸æ•°
CHECKPOINT_FILE = 'alpha_checkpoint.csv'

def segmented_sieve(limit, segment_size=10**6):
    """
    åˆ†æ®µç­›æ³• - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
    è¿”å›æ‰€æœ‰å°äºç­‰äºlimitçš„ç´ æ•°
    """
    print(f"ğŸ“¦ ä½¿ç”¨åˆ†æ®µç­›æ³•ç”Ÿæˆç´ æ•° (limit={limit:,})...")
    t0 = time.time()
    
    # é¦–å…ˆç­›å‡ºsqrt(limit)ä»¥å†…çš„ç´ æ•°
    sqrt_limit = int(limit**0.5) + 1
    small_sieve = np.ones(sqrt_limit, dtype=bool)
    small_sieve[0:2] = False
    
    for i in range(2, int(sqrt_limit**0.5) + 1):
        if small_sieve[i]:
            small_sieve[i*i::i] = False
    
    small_primes = np.nonzero(small_sieve)[0]
    
    # æ”¶é›†æ‰€æœ‰ç´ æ•°
    all_primes = list(small_primes)
    
    # åˆ†æ®µç­›
    for low in range(sqrt_limit, limit + 1, segment_size):
        high = min(low + segment_size, limit + 1)
        segment = np.ones(high - low, dtype=bool)
        
        for p in small_primes:
            if p * p > high:
                break
            # æ‰¾åˆ°segmentä¸­ç¬¬ä¸€ä¸ªpçš„å€æ•°
            start = ((low + p - 1) // p) * p - low
            if start < 0:
                start += p
            segment[start::p] = False
        
        # æ·»åŠ è¿™ä¸ªsegmentä¸­çš„ç´ æ•°
        segment_primes = np.nonzero(segment)[0] + low
        all_primes.extend(segment_primes)
        
        # è¿›åº¦
        if (high - sqrt_limit) % (10 * segment_size) < segment_size:
            progress = (high - sqrt_limit) / (limit - sqrt_limit) * 100
            print(f"   ç­›æ³•è¿›åº¦: {progress:.1f}%")
    
    primes = np.array(all_primes, dtype=np.int64)
    elapsed = time.time() - t0
    print(f"   âœ“ å®Œæˆ! æ‰¾åˆ° {len(primes):,} ä¸ªç´ æ•° ({elapsed:.1f}ç§’)")
    
    return primes

def get_primes_simple(max_n):
    """ç®€å•ç­›æ³•ï¼ˆé€‚ç”¨äºå†…å­˜å……è¶³çš„æƒ…å†µï¼‰"""
    print(f"ğŸ“¦ ç”Ÿæˆç´ æ•°è¡¨ (æœ€å¤§å€¼: {max_n:,})...")
    t0 = time.time()
    
    try:
        sieve = np.ones(max_n + 1, dtype=np.bool_)
        sieve[0:2] = False
        
        for i in range(2, int(np.sqrt(max_n)) + 1):
            if sieve[i]:
                sieve[i*i::i] = False
        
        primes = np.nonzero(sieve)[0]
        elapsed = time.time() - t0
        print(f"   âœ“ å®Œæˆ! æ‰¾åˆ° {len(primes):,} ä¸ªç´ æ•° ({elapsed:.1f}ç§’)")
        return primes
    except MemoryError:
        print("   å†…å­˜ä¸è¶³ï¼Œåˆ‡æ¢åˆ°åˆ†æ®µç­›æ³•...")
        return segmented_sieve(max_n)

def get_singular_series_vectorized(n_array):
    """å‘é‡åŒ–è®¡ç®—å¥‡å¼‚çº§æ•°"""
    results = np.ones(len(n_array))
    
    for idx, n in enumerate(n_array):
        if n % 2 != 0:
            results[idx] = 0
            continue
            
        temp = n
        while temp % 2 == 0:
            temp //= 2
        
        d = 3
        while d * d <= temp:
            if temp % d == 0:
                results[idx] *= (d - 1) / (d - 2)
                while temp % d == 0:
                    temp //= d
            d += 2
        if temp > 1:
            results[idx] *= (temp - 1) / (temp - 2)
    
    return results

def predict_simple(n):
    """ç®€åŒ–é¢„æµ‹ï¼ˆé¿å…ç§¯åˆ†çš„å¼€é”€ï¼‰"""
    # Li2(n) â‰ˆ n/lnÂ²(n) Ã— (1 + 2/ln(n) + ...)
    ln_n = np.log(n)
    return n / (ln_n ** 2) * (1 + 2/ln_n + 6/ln_n**2)

def count_goldbach_fast(n, primes, primes_set):
    """å¿«é€Ÿè®¡ç®—G(N)"""
    limit = n // 2
    idx = np.searchsorted(primes, limit, side='right')
    
    count = 0
    for p in primes[:idx]:
        if (n - p) in primes_set:
            count += 1
    
    # Ordered count
    g_n = count * 2
    if n % 2 == 0 and (n // 2) in primes_set:
        g_n -= 1
    
    return g_n

def load_checkpoint():
    """åŠ è½½æ–­ç‚¹"""
    if os.path.exists(CHECKPOINT_FILE):
        df = pd.read_csv(CHECKPOINT_FILE)
        last_n = df['N'].max()
        print(f"ğŸ“‚ å‘ç°æ–­ç‚¹æ–‡ä»¶ï¼Œä» N={last_n:,} ç»§ç»­...")
        return df.to_dict('records'), last_n
    return [], 0

def save_checkpoint(results):
    """ä¿å­˜æ–­ç‚¹"""
    df = pd.DataFrame(results)
    df.to_csv(CHECKPOINT_FILE, index=False)

def run_sampling():
    """ä¸»é‡‡æ ·å‡½æ•°"""
    print("=" * 70)
    print("ğŸš€ Paper III: Î± Evolution Generator (Optimized)")
    print("=" * 70)
    print(f"\nç›®æ ‡: N = {START_N:,} â†’ {END_N:,}")
    
    # åŠ è½½æ–­ç‚¹
    results, last_n = load_checkpoint()
    
    # ç”Ÿæˆç´ æ•°
    primes = get_primes_simple(END_N)
    primes_set = set(primes)
    
    # ç”Ÿæˆé‡‡æ ·ç‚¹
    n_decades = np.log10(END_N / START_N)
    total_points = int(n_decades * POINTS_PER_DECADE)
    
    targets = np.logspace(np.log10(START_N), np.log10(END_N), total_points)
    targets = np.unique(targets.astype(np.int64))
    targets = [t if t % 2 == 0 else t + 1 for t in targets]
    targets = sorted(set(targets))
    
    # è·³è¿‡å·²å®Œæˆçš„
    if last_n > 0:
        targets = [t for t in targets if t > last_n]
    
    print(f"\nğŸ“Š é‡‡æ ·ç‚¹: {len(targets)} (è·³è¿‡å·²å®Œæˆ: {len(results)})")
    
    # å¼€å§‹é‡‡æ ·
    start_time = time.time()
    checkpoint_interval = 50
    
    for i, n in enumerate(targets):
        # è®¡ç®—
        g_n = count_goldbach_fast(n, primes, primes_set)
        sn = get_singular_series_vectorized(np.array([n]))[0]
        pred_simple = 2 * C2 * sn * predict_simple(n)
        
        results.append({
            'N': n,
            'G_N': g_n,
            'S_N': sn,
            'Pred': pred_simple,
            'Residual': g_n - pred_simple,
            'Bias': (g_n - pred_simple) / pred_simple * 100 if pred_simple > 0 else 0
        })
        
        # è¿›åº¦å’Œæ–­ç‚¹
        if (i + 1) % checkpoint_interval == 0:
            elapsed = time.time() - start_time
            rate = (i + 1) / elapsed
            eta = (len(targets) - i - 1) / rate if rate > 0 else 0
            
            print(f"   [{i+1}/{len(targets)}] N={n:,} | G={g_n:,} | "
                  f"é€Ÿåº¦:{rate:.1f}/s | å‰©ä½™:{eta/60:.1f}åˆ†é’Ÿ")
            
            # ä¿å­˜æ–­ç‚¹
            save_checkpoint(results)
    
    # æœ€ç»ˆä¿å­˜
    df = pd.DataFrame(results)
    output_file = 'ALPHA_EVOLUTION_100M.csv'
    df.to_csv(output_file, index=False)
    
    # åˆ é™¤æ–­ç‚¹æ–‡ä»¶
    if os.path.exists(CHECKPOINT_FILE):
        os.remove(CHECKPOINT_FILE)
    
    total_time = time.time() - start_time
    print(f"\nâœ… å®Œæˆ! æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    print(f"   æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    
    # å¿«é€ŸÎ±åˆ†æ
    analyze_alpha(df)
    
    return df

def analyze_alpha(df):
    """å¿«é€ŸÎ±åˆ†æ"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ Î± æ¼”åŒ–åˆ†æ")
    print("=" * 70)
    
    bins = np.logspace(np.log10(df['N'].min()), np.log10(df['N'].max()), 12)
    
    print(f"\n{'NèŒƒå›´':<25} {'Î±':<10} {'æ ·æœ¬é‡':<10}")
    print("-" * 50)
    
    alpha_list = []
    for i in range(len(bins) - 1):
        low, high = bins[i], bins[i+1]
        subset = df[(df['N'] >= low) & (df['N'] < high)]
        
        if len(subset) > 10:
            residuals = subset['G_N'] - subset['Pred']
            var_g = residuals.var()
            mean_g = subset['Pred'].mean()
            alpha = var_g / mean_g
            alpha_list.append(alpha)
            
            label = f"{low:.1e}-{high:.1e}"
            print(f"{label:<25} {alpha:<10.4f} {len(subset):<10}")
    
    if len(alpha_list) > 0:
        mean_alpha = np.mean(alpha_list[-5:]) if len(alpha_list) >= 5 else np.mean(alpha_list)
        print(f"\næœ€åå‡ ä¸ªbinçš„å¹³å‡Î±: {mean_alpha:.4f}")
        
        if mean_alpha < 0.55:
            print("âœ… æ”¯æŒ GUE å‡è®¾ (Î± â†’ 0.5)")
        elif mean_alpha > 0.7:
            print("âš ï¸ å¯èƒ½è¶‹å‘ Poisson (Î± â†’ 1.0)")
        else:
            print("ğŸ”¶ è¿‡æ¸¡åŒºåŸŸï¼Œéœ€è¦æ›´å¤§NéªŒè¯")

if __name__ == "__main__":
    # æ£€æŸ¥å†…å­˜
    try:
        import psutil
        available_gb = psutil.virtual_memory().available / (1024**3)
        required_gb = END_N / 1e9 * 1.2
        
        print(f"\nç³»ç»Ÿä¿¡æ¯:")
        print(f"  å¯ç”¨å†…å­˜: {available_gb:.1f} GB")
        print(f"  é¢„è®¡éœ€è¦: {required_gb:.1f} GB")
        
        if available_gb < required_gb:
            print(f"\nâš ï¸ å†…å­˜å¯èƒ½ä¸è¶³ï¼")
            print(f"   å»ºè®®: å‡å°‘END_Næˆ–ä½¿ç”¨åˆ†æ®µç­›æ³•")
            response = input("   ç»§ç»­? (y/n): ")
            if response.lower() != 'y':
                sys.exit(0)
    except ImportError:
        pass
    
    df = run_sampling()
